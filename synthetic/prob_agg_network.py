# -*- coding: utf-8 -*-
"""prob_agg_network

Automatically generated by Colaboratory.

Original file is located at
	https://colab.research.google.com/drive/1JveMrFKUmuOBya9HmanszPEUga3SfHbs
"""

import torch
import torchvision
import torchvision.transforms as transforms

import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torch.distributions as dists

import numpy as np
import matplotlib.pyplot as plt


#Make dataloaders
transform = transforms.ToTensor()

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
										download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=10,
											shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
									   download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=10,
										 shuffle=False, num_workers=2)


#Network architecture
class Net(nn.Module):
	def __init__(self):
		super(Net, self).__init__()
		self.conv1 = nn.Conv2d(3,16,3)
		self.conv2 = nn.Conv2d(16,32,3)
		self.conv3 = nn.Conv2d(32,2,3)
		
	def forward(self, x):
		x = F.relu(self.conv1(x))
		x = F.relu(self.conv2(x))
		x = F.softplus(self.conv3(x))
		return x


#Initialize groound truth network
trainiter = iter(trainloader)
images, _ = trainiter.next()

D_gt = Net()
for param in D_gt.parameters():
	param.requires_grad = False

output = D_gt(images)

#View some examples
fig, ax = plt.subplots(10,2)
for i in range(10):
	ax[i,0].imshow(images[i].numpy().transpose(1,2,0))
	ax[i,1].imshow(output[i][1])


#Aggregate distributions within Voronoi cells
def voronoi_agg_dist(input, rand, d=20):
	torch.manual_seed(rand)
	N,_,H,W = input.size()
	
	while True:
		target_pts = torch.randint(0, H, (d,2)) #Assume square images (H == W)
		#target_pts = torch.rand(d,2) * H
		lattice_pts = torch.cartesian_prod(torch.arange(H), torch.arange(W))

		dists = torch.cdist(target_pts.type(torch.DoubleTensor),
							lattice_pts.type(torch.DoubleTensor))
		labels = torch.argmin(dists, dim=0).view(H,W)

		if all(i in labels for i in range(d)):
			break
	
	output = torch.Tensor(N,d,2)
	for i in range(d):
		output[:,i,0] = (input[:,0] * (labels == i)).sum(dim=(1,2))
		output[:,i,1] = (input[:,1] * (labels == i)).pow(2.0).sum(dim=(1,2)).pow(0.5)
	
	return output


#Aggregate image values within Voronoi cells
def voronoi_agg_img(input, rand=0, d=20):
	torch.manual_seed(rand)
	N,H,W = input.size()

	target_pts = torch.randint(0, H, (d,2)) #Assume square images (H == W)
	lattice_pts = torch.cartesian_prod(torch.arange(H), torch.arange(W))

	dists = torch.cdist(target_pts.type(torch.DoubleTensor),
						lattice_pts.type(torch.DoubleTensor))
	labels = torch.argmin(dists, dim=0).view(H,W)
	
	output = torch.Tensor(N,d)
	for i in range(d):
		output[:,i] = (input * (labels == i)).sum(dim=(1,2))
	
	return output


#Initialize and train network to match groound truth
D_tr = Net()
optimizer = optim.Adam(D_tr.parameters(),lr=1e-4)

for epoch in range(3):
	running_loss = 0.0
	for i, data in enumerate(trainloader):
		inputs, _ = data

		rand = torch.randint(10000, (1,)).item()
		
		#Compute outputs and aggregate
		gt_outputs = D_gt(inputs)
		gt_img = dists.Normal(gt_outputs[:,0], gt_outputs[:,1]).sample()
		agg_img = voronoi_agg_img(gt_img, rand, 5)

		tr_outputs = D_tr(inputs)
		agg_dist = voronoi_agg_dist(tr_outputs, rand, 5)
		

		#Calculate loss and backprop
		losses = -dists.Normal(agg_dist[:,:,0], agg_dist[:,:,1]).log_prob(agg_img)
		loss = losses.sum()

		optimizer.zero_grad()
		loss.backward()
		optimizer.step()

		#Show running loss
		running_loss += loss.item()
		if i % 500 == 499:
			print('[%d, %5d] loss: %.4f' %
				(epoch + 1, i + 1, running_loss / 500))
			running_loss = 0.0

print('Finished training')

#View examples from ground truth and trained networks
testiter = iter(testloader)
images, _ = testiter.next()

output_gt = D_gt(images)
output_tr = D_tr(images)

fig, ax = plt.subplots(10,3)
for i in range(10):
	for j in range(3):
		ax[i,j].axis('off')
	ax[i,0].imshow(images[i].numpy().transpose(1,2,0))
	ax[i,1].imshow(output_gt[i][0])
	ax[i,2].imshow(output_tr[i][0].detach())
plt.tight_layout(3e-1)

